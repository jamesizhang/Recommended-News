# 新闻推荐系统项目

## 项目概述
基于天池新闻推荐赛数据集，设计并实现了一套完整的新闻推荐系统。**核心创新点是将Transformer架构应用于推荐系统，实现生成式召回和排序**。通过next-token prediction方式训练，Transformer模型既可以用于召回阶段（TopK检索），也可以直接用于排序预测，实现端到端的推荐。系统还集成了ItemCF、Embedding、Word2Vec、YouTubeDNN等传统召回方法作为补充，处理30万用户、近300万次点击、36万篇新闻文章的大规模数据。

## 技术栈
- **编程语言**: Python
- **深度学习框架**: PyTorch, TensorFlow/Keras
- **机器学习**: LightGBM, scikit-learn
- **数据处理**: Pandas, NumPy
- **向量检索**: FAISS
- **序列建模**: Word2Vec, Transformer
- **其他**: tqdm, pickle

## 核心功能与实现

### 1. Transformer生成式召回/排序（核心创新）

**模型架构**：
- 基于Transformer Encoder架构，使用自注意力机制捕获用户行为序列的长期依赖关系
- 通过next-token prediction方式训练，将推荐问题转化为序列生成问题
- 支持用户ID embedding、用户特征（操作系统、设备组、地区等）和物品特征（字数、预训练embedding等）的端到端融合

**技术实现**：
- 使用位置编码（Positional Encoding）建模序列顺序信息
- 采用causal mask确保自回归训练的正确性
- 输出层投影到物品词汇表，输出每个物品的logits分数
- 支持批量推理，通过TopK检索实现高效召回

**应用场景**：
- **召回阶段**：取模型输出的logits分数，通过TopK检索获取候选物品
- **排序阶段**：直接使用logits分数进行排序，无需额外的排序模型
- **端到端推荐**：一个模型同时完成召回和排序，简化推荐系统架构

**技术优势**：
- 相比传统方法，能够更好地捕获用户行为序列的复杂模式
- 支持用户和物品特征的深度融合
- 实现召回和排序的统一建模，减少系统复杂度

### 2. 多路召回策略（Recall）
实现了5种召回策略，通过加权融合提升召回覆盖率：

- **协同过滤召回**
  - ItemCF：基于物品共现矩阵计算相似度，支持时间衰减和热度惩罚

- **向量召回**
  - Embedding相似度召回：利用预训练的文章embedding向量（249维），通过余弦相似度进行召回
  - Word2Vec召回：基于用户点击序列训练Word2Vec模型学习物品embedding，通过计算物品相似度矩阵进行召回
  - YouTubeDNN召回：使用深度神经网络学习用户embedding（输入包括用户ID和历史点击序列），通过平均池化聚合历史点击序列，然后使用FAISS进行向量检索，通过用户embedding搜索相似的物品embedding

### 3. 特征工程（Feature Engineering）
构建了丰富的用户-物品特征体系：

- **用户特征**
  - 用户历史行为统计：点击次数、活跃度、时间偏好
  - 用户设备信息：操作系统、设备组、地区、来源类型
  - 用户兴趣偏好：偏好类别、平均阅读字数

- **物品特征**
  - 文章属性：类别ID、字数、创建时间
  - 文章Embedding：249维预训练向量

- **交互特征**
  - 物品-物品相似度：历史点击文章与候选文章的embedding相似度（使用预训练embedding计算点积），包括相似度的最大值、最小值、总和、均值等统计特征
  - 时间特征：点击时间差、文章创建时间差
  - 序列特征：用户历史点击序列的统计特征（点击次数、活跃度等）

### 4. 排序模型（Ranking）
实现了多种排序策略：

- **Transformer直接排序**（核心创新）
  - Transformer模型输出每个物品的logits分数，可以直接用于排序预测
  - 通过next-token prediction学习用户行为序列，输出物品概率分布
  - 支持端到端的推荐，无需额外的排序模型

- **LightGBM排序**
  - 使用LGBMRanker进行pairwise排序
  - 特征包括用户特征、物品特征、交互特征等24维特征
  - 通过NDCG指标进行模型评估和优化

- **DIN模型（深度兴趣网络）**
  - 使用注意力机制捕获用户对不同物品的兴趣强度
  - 结合用户行为序列和候选物品特征进行个性化排序

- **模型融合**
  - 对LightGBM和DIN模型的预测结果进行加权融合
  - 通过验证集调优融合权重，提升最终推荐效果

### 5. 数据分析与可视化
- 用户行为分析：点击分布、重复点击统计、环境变化分析
- 物品分析：热门文章分布、类别分布、字数分布
- 共现分析：文章共现频次、用户兴趣多样性
- 时间序列分析：点击时间模式、文章相似度变化

## 项目亮点

1. **Transformer生成式推荐（核心创新）**：
   - **创新性**：首次将Transformer架构应用于推荐系统的召回和排序阶段，探索生成式推荐的可能性
   - **技术突破**：通过next-token prediction方式，将推荐问题转化为序列生成问题，能够更好地捕获用户行为序列的复杂模式
   - **架构优势**：一个模型同时完成召回和排序，简化推荐系统架构，实现端到端的推荐
   - **特征融合**：支持用户ID、用户特征（设备、地区等）和物品特征（字数、embedding等）的深度融合
   - **灵活性**：模型输出物品logits分数，既可以用于召回（TopK检索），也可以直接用于排序预测

2. **多策略融合召回**：集成5种召回策略（ItemCF、Embedding、Word2Vec、YouTubeDNN、Transformer），通过加权融合提升召回覆盖率和多样性，有效解决冷启动问题

3. **完整的推荐系统 pipeline**：从数据预处理、召回、特征工程到排序，构建了完整的推荐系统流程

4. **大规模数据处理**：针对30万用户、300万点击的大规模数据，实现了内存优化和高效的数据处理流程，支持批量推理和高效检索

5. **模型评估体系**：实现了召回率、NDCG等指标评估，支持离线验证和线上效果评估

## 项目成果
- **核心成果**：创新性地将Transformer应用于推荐系统，实现生成式召回和排序，探索了端到端推荐的可能性
- 实现了完整的推荐系统架构，涵盖召回、排序全流程
- Transformer模型支持用户和物品特征的深度融合，能够更好地捕获用户行为序列模式
- 通过多策略融合（5种召回策略），提升了推荐系统的覆盖率和准确性
- 构建了可扩展的特征工程框架，支持快速迭代和优化

## 技术难点与解决方案

1. **Transformer在推荐系统中的应用**（核心难点）：
   - **挑战**：如何将Transformer架构适配到推荐场景，处理用户行为序列和物品特征
   - **解决方案**：
     - 设计用户-物品混合输入格式，第一个位置使用用户embedding，后续位置使用物品序列
     - 实现用户特征和物品特征的深度融合机制（concat + Linear投影）
     - 使用causal mask确保自回归训练的正确性
     - 设计灵活的推理接口，支持召回（TopK检索）和排序（直接使用logits）两种模式

2. **序列建模与长期依赖**：
   - 使用位置编码（Positional Encoding）建模序列顺序信息
   - 通过多头注意力机制捕获用户行为序列的长期依赖关系
   - 支持变长序列处理，通过padding和mask机制处理不同长度的用户序列

3. **大规模数据训练与推理**：
   - 实现批量训练和推理，支持GPU加速
   - 优化内存使用，支持大规模物品词汇表（36万+物品）
   - 实现高效的TopK检索，支持召回阶段的快速推理

4. **冷启动问题**：通过多路召回策略（热门文章、类别召回等）和用户特征建模解决新用户和新物品的推荐问题

5. **特征工程**：构建了24维特征体系，包括统计特征、交互特征、序列特征。对DIN模型的dense特征和Transformer的物品特征使用MinMaxScaler进行归一化处理，提升模型训练效果

6. **模型融合**：通过加权融合LightGBM和DIN模型，结合树模型的记忆能力和深度模型的泛化能力

## 项目文件结构
- `news1.py`: ItemCF协同过滤实现
- `news2.py`: 数据分析和可视化
- `news3.py`: 多路召回策略实现
- `news3_transformer.py`: Transformer生成式召回模型
- `news4.py`: 特征工程实现
- `news5.py`: 排序模型实现（LightGBM + DIN）

